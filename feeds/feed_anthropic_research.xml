<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Anthropic Research</title>
    <link>https://anthropic.com/research/feed_anthropic_research.xml</link>
    <description>Latest research from Anthropic</description>
    <atom:link href="https://anthropic.com/research/feed_anthropic_research.xml" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <image>
      <url>https://www.anthropic.com/images/icons/apple-touch-icon.png</url>
      <title>Anthropic Research</title>
      <link>https://anthropic.com/research/feed_anthropic_research.xml</link>
    </image>
    <language>en</language>
    <lastBuildDate>Mon, 23 Feb 2026 20:10:55 +0000</lastBuildDate>
    <item>
      <title>Societal Impacts</title>
      <link>https://www.anthropic.com/research/team/societal-impacts</link>
      <description>Societal Impacts</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/team/societal-impacts</guid>
      <category>Research</category>
    </item>
    <item>
      <title>Interpretability</title>
      <link>https://www.anthropic.com/research/team/interpretability</link>
      <description>Interpretability</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/team/interpretability</guid>
      <category>Research</category>
    </item>
    <item>
      <title>Economic Research</title>
      <link>https://www.anthropic.com/research/team/economic-research</link>
      <description>Economic Research</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/team/economic-research</guid>
      <category>Research</category>
    </item>
    <item>
      <title>Alignment</title>
      <link>https://www.anthropic.com/research/team/alignment</link>
      <description>Alignment</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/team/alignment</guid>
      <category>Research</category>
    </item>
    <item>
      <title>AlignmentDec 18, 2024Alignment faking in large language modelsThis paper provides the first empirical example of a model engaging in alignment faking without being trained to do so—selectively complying with training objectives while strategically preserving existing preferences.</title>
      <link>https://www.anthropic.com/research/alignment-faking</link>
      <description>AlignmentDec 18, 2024Alignment faking in large language modelsThis paper provides the first empirical example of a model engaging in alignment faking without being trained to do so—selectively complying with training objectives while strategically preserving existing preferences.</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/alignment-faking</guid>
      <category>Research</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>AlignmentFeb 3, 2025Constitutional Classifiers: Defending against universal jailbreaksThese classifiers filter the overwhelming majority of jailbreaks while maintaining practical deployment. A prototype withstood over 3,000 hours of red teaming with no universal jailbreak discovered.</title>
      <link>https://www.anthropic.com/research/constitutional-classifiers</link>
      <description>AlignmentFeb 3, 2025Constitutional Classifiers: Defending against universal jailbreaksThese classifiers filter the overwhelming majority of jailbreaks while maintaining practical deployment. A prototype withstood over 3,000 hours of red teaming with no universal jailbreak discovered.</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/constitutional-classifiers</guid>
      <category>Research</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>InterpretabilityMar 27, 2025Tracing the thoughts of a large language modelCircuit tracing lets us watch Claude think, uncovering a shared conceptual space where reasoning happens before being translated into language—suggesting the model can learn something in one language and apply it in another.</title>
      <link>https://www.anthropic.com/research/tracing-thoughts-language-model</link>
      <description>InterpretabilityMar 27, 2025Tracing the thoughts of a large language modelCircuit tracing lets us watch Claude think, uncovering a shared conceptual space where reasoning happens before being translated into language—suggesting the model can learn something in one language and apply it in another.</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/tracing-thoughts-language-model</guid>
      <category>Research</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>InterpretabilityOct 29, 2025Signs of introspection in large language modelsCan Claude access and report on its own internal states? This research finds evidence for a limited but functional ability to introspect—a step toward understanding what's actually happening inside these models.</title>
      <link>https://www.anthropic.com/research/introspection</link>
      <description>InterpretabilityOct 29, 2025Signs of introspection in large language modelsCan Claude access and report on its own internal states? This research finds evidence for a limited but functional ability to introspect—a step toward understanding what's actually happening inside these models.</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/introspection</guid>
      <category>Research</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Project Vend: Phase two</title>
      <link>https://www.anthropic.com/research/project-vend-2</link>
      <description>Project Vend: Phase two</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/project-vend-2</guid>
      <category>Research</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Jan 9, 2026AlignmentNext-generation Constitutional Classifiers: More efficient protection against universal jailbreaks</title>
      <link>https://www.anthropic.com/research/next-generation-constitutional-classifiers</link>
      <description>Jan 9, 2026AlignmentNext-generation Constitutional Classifiers: More efficient protection against universal jailbreaks</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/next-generation-constitutional-classifiers</guid>
      <category>Research</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Jan 15, 2026Economic ResearchAnthropic Economic Index report: economic primitives</title>
      <link>https://www.anthropic.com/research/anthropic-economic-index-january-2026-report</link>
      <description>Jan 15, 2026Economic ResearchAnthropic Economic Index report: economic primitives</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/anthropic-economic-index-january-2026-report</guid>
      <category>Research</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Jan 15, 2026Economic ResearchAnthropic Economic Index: New building blocks for understanding AI use</title>
      <link>https://www.anthropic.com/research/economic-index-primitives</link>
      <description>Jan 15, 2026Economic ResearchAnthropic Economic Index: New building blocks for understanding AI use</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/economic-index-primitives</guid>
      <category>Research</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Jan 19, 2026InterpretabilityThe assistant axis: situating and stabilizing the character of large language models</title>
      <link>https://www.anthropic.com/research/assistant-axis</link>
      <description>Jan 19, 2026InterpretabilityThe assistant axis: situating and stabilizing the character of large language models</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/assistant-axis</guid>
      <category>Research</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Jan 28, 2026AlignmentDisempowerment patterns in real-world AI usage</title>
      <link>https://www.anthropic.com/research/disempowerment-patterns</link>
      <description>Jan 28, 2026AlignmentDisempowerment patterns in real-world AI usage</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/disempowerment-patterns</guid>
      <category>Research</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Jan 29, 2026AlignmentHow AI assistance impacts the formation of coding skills</title>
      <link>https://www.anthropic.com/research/AI-assistance-coding-skills</link>
      <description>Jan 29, 2026AlignmentHow AI assistance impacts the formation of coding skills</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/AI-assistance-coding-skills</guid>
      <category>Research</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Feb 16, 2026Economic ResearchIndia Country Brief: The Anthropic Economic Index</title>
      <link>https://www.anthropic.com/research/india-brief-economic-index</link>
      <description>Feb 16, 2026Economic ResearchIndia Country Brief: The Anthropic Economic Index</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/india-brief-economic-index</guid>
      <category>Research</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Feb 18, 2026Societal ImpactsMeasuring AI agent autonomy in practice</title>
      <link>https://www.anthropic.com/research/measuring-agent-autonomy</link>
      <description>Feb 18, 2026Societal ImpactsMeasuring AI agent autonomy in practice</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/measuring-agent-autonomy</guid>
      <category>Research</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Feb 23, 2026Societal ImpactsAnthropic Education Report: The AI Fluency Index</title>
      <link>https://www.anthropic.com/research/AI-fluency-index</link>
      <description>Feb 23, 2026Societal ImpactsAnthropic Education Report: The AI Fluency Index</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/AI-fluency-index</guid>
      <category>Research</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>
